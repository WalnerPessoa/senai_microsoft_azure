{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat_minor": 2,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "Module 3, Lab 3 - Causal Claims\n===============================\n\nIn this lab, we briefly explore the causal claim. Recall that if you\nwant to truly understand your variables, you want to draw cause-effect\nconclusions. \n\nIn this lab, we will use the `effsize` package for measuring effect size\nand the `ggplot2` package for data visualization. We will also briefly\nexplore the `ggridges` package.\n\n___\n\nMódulo 3, Laboratório 3 - Reivindicações causais\n====\nNeste laboratório, exploramos brevemente a afirmação causal. Lembre-se de que, se você deseja realmente compreender suas variáveis, deve tirar conclusões de causa-efeito.\n\nNeste laboratório, usaremos o pacote effsize para medir o tamanho do efeito e o pacote ggplot2 para visualização de dados. Também exploraremos brevemente o pacote ggridges.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#### LOAD PACKAGES ####\nfrom scipy import stats\nimport scipy.stats as ss\nimport pandas as pd\nimport numpy as np\nimport statsmodels.stats.weightstats as ws\nfrom statsmodels.stats.power import tt_ind_solve_power\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Weaknesses of Association Claims for Deep Understanding\n========================================================\n\nAssociation claims are useful; they let you know what variables correlate\nwith each other. However, they don't tell you what will happen if you\nintervene and act in the world in new ways. For example, imagine you have\nbeen analyzing data at your organization and find that employees who are\nless stressed tend to be more productive. It may be very unclear *why* that\nrelationship exists. Some possibilities include:\n\n1.  Stress reduces productivity\n2.  Productivity reduces stress\n3.  Some other variable is causing both of them\n___\n\n\nFraquezas das reivindicações de associação para compreensão profunda¶\n\nAs reivindicações de associação são úteis; eles permitem que você saiba quais variáveis ​​se correlacionam entre si. No entanto, eles não lhe dizem o que acontecerá se você intervir e agir no mundo de novas maneiras. Por exemplo, imagine que você está analisando dados em sua organização e descobre que os funcionários menos estressados ​​tendem a ser mais produtivos. Pode não estar muito claro por que existe esse relacionamento. Algumas possibilidades incluem:\n\n1. Estresse reduz a produtividade\n2. Produtividade reduz o estresse\n3. Alguma outra variável está causando os dois\n\n___\nIt is worth putting real thought into all of these.\n\n1.  For example, it is reasonable that stress reduces productivity.\n2.  However, it is also reasonable that getting things done may take\n    stress off of the shoulders of employees as they clear projects off\n    their to-do lists.\n3.  It is also possible that something else may be casing both high\n    stress and low productivity, such as obligations outside of work,\n    health issues, etc.\n___\n\nVale a pena colocar um pensamento real em tudo isso.\n\n1. Por exemplo, é razoável que o estresse reduza a produtividade.\n2. No entanto, também é razoável que fazer as coisas possam tirar o estresse dos ombros dos funcionários enquanto eles eliminam os projetos de suas listas de tarefas pendentes.\n3. Também é possível que outra coisa possa estar envolvendo alto estresse e baixa produtividade, como obrigações fora do trabalho, problemas de saúde, etc.\n\n\n___\nAll three of these have different implications for how to increase\nproductivity:\n\n1.  The first possibility suggests that reducing stress might actually\n    help.\n2.  The second possibility suggests that reducing stress will not help\n    (but finding other contributors to productivity might, so we should\n    go looking for those). Time for more research!\n3.  The third possibility suggests that attempts to reduce stress would\n    do nothing to increase productivity because the real problem is the\n    unmeasured *prior cause* of the stress. For example, if health\n    issues are causing people to be more stressed and less productive,\n    then the desired boost to productivity will not come from reducing\n    stress but from fixing the underlying health issues.\n\n___\n\nTodos os três têm implicações diferentes sobre como aumentar a produtividade:\n\n1. A primeira possibilidade sugere que reduzir o estresse pode realmente ajudar.\n2. A segunda possibilidade sugere que reduzir o estresse não vai ajudar (mas encontrar outros fatores que contribuem para a produtividade pode, então devemos procurá-los). É hora de mais pesquisas!\n3. A terceira possibilidade sugere que as tentativas de reduzir o estresse não fariam nada para aumentar a produtividade, porque o problema real é a causa anterior não medida do estresse. Por exemplo, se os problemas de saúde estão fazendo com que as pessoas fiquem mais estressadas e menos produtivas, o aumento desejado na produtividade não virá da redução do estresse, mas da correção dos problemas de saúde subjacentes.\n\n___\n\nIn conclusion, association claims are limited in their ability to help\nyou draw cause-effect conclusions. Or, to put it differently, we could\n*predict* the productivity of an employee given their stress levels, but\nwe wouldn't know how to actually *improve* productivity given this\ninformation. Association claims simply don't really tell you what is\ncausing what.\n___\nEm conclusão, as alegações de associação são limitadas em sua capacidade de ajudá-lo a tirar conclusões de causa-efeito. Ou, em outras palavras, poderíamos prever a produtividade de um funcionário considerando seus níveis de estresse, mas não saberíamos como realmente melhorar a produtividade com essas informações. As reivindicações da associação simplesmente não dizem o que está causando o quê.\nSolução: o experimento\n\n___\nSolution: The Experiment\n========================\n\nTo solve this problem, we run an experiment. Imagine we randomly assign\n250 employees to either a stress-reduction treatment or a \"business-as-usual\"\ncontrol group. After 7 weeks, the productivity of these employees is\nassessed.\n___\nPara resolver esse problema, fazemos um experimento. Imagine que atribuímos aleatoriamente 250 funcionários a um tratamento de redução de estresse ou a um grupo de controle \"business-as-usual\". Após 7 semanas, a produtividade desses funcionários é avaliada.\n\n___\nBecause employees are *randomly* assigned to groups *by the researcher*,\nthe research can be confident that\n\n-   The two groups were approximately equal to begin with (this can be\n    checked, if desired)\n-   Any differences at the end of the study are due to the treatment\n___\nComo os funcionários são designados aleatoriamente a grupos pelo pesquisador, a pesquisa pode ter certeza de que\n\n- Os dois grupos eram aproximadamente iguais para começar (isso pode ser verificado, se desejado)\n- Quaisquer diferenças no final do estudo são devido ao tratamento\n\n___\nWe can draw this conclusion because we will be very careful to treat the\ngroups *identically* in every way, except for the treatment. We must be\n**exceedingly** careful on this point, as any unintended differences in\ntreatment (the messaging we give them, the scheduling, workload, etc.)\ncould accidentally cause a second systematic difference between our\ngroups, and then we would not be sure what was really responsible for\nany effects we end up seeing. This is known as a *confound* and it would\nrun our experiment. We will be very sure not to allow this to happen,\nusing strict protocols, scripts, email templates, etc. We would be very\ncareful to manage expectations so neither group had different\nexpectations (possibly keeping our employees blind to some of the\ndetails, or keeping managers in the dark). Our goal will be to keep\n**everything the same between our groups**, tangibly and mentally,\nexcept for the actual treatment itself. This will take very detailed and\nrigorous planning, but it is worth it. A small-scale pilot of an\nintervention program will take some rigorous planning, but it is much\nless expensive than rolling out a company-wide stress program only to\nfind it is a waste of money and ineffective (as might happen in many\norganizations).\n___\n\nPodemos tirar essa conclusão porque seremos muito cuidadosos em tratar os grupos de forma idêntica em todos os sentidos, exceto no tratamento. Devemos ser extremamente cuidadosos neste ponto, pois quaisquer diferenças não intencionais no tratamento (a mensagem que damos a eles, a programação, carga de trabalho, etc.) podem causar acidentalmente uma segunda diferença sistemática entre nossos grupos, e então não teríamos certeza do que foi realmente responsáveis ​​por quaisquer efeitos que acabamos vendo. Isso é conhecido como confuso e executaria nosso experimento. Teremos a certeza de não permitir que isso aconteça, usando protocolos rígidos, scripts, modelos de e-mail, etc. Teríamos muito cuidado ao gerenciar as expectativas para que nenhum dos grupos tivesse expectativas diferentes (possivelmente mantendo nossos funcionários cegos para alguns dos detalhes, ou mantendo os gerentes no escuro). Nosso objetivo será manter tudo igual entre nossos grupos, tangível e mentalmente, exceto para o próprio tratamento em si. Isso vai exigir um planejamento muito detalhado e rigoroso, mas vale a pena. Um piloto em pequena escala de um programa de intervenção exigirá um planejamento rigoroso, mas é muito menos caro do que implantar um programa de estresse em toda a empresa apenas para descobrir que é um desperdício de dinheiro e ineficaz (como pode acontecer em muitas organizações).\n___\nAnalyzing the Experiment\n========================\n\nTo analyze the experiment, a simple independent-groups *t*-test can be\nperformed. This compares the means of the two groups to determine if\nthey are statistically significantly different.\n\nImagine the study is done; the data are called \"causal.csv\" and are in\nthe github folder for this lab.\n___\n\nAnalisando o experimento\n=====\nPara analisar o experimento, um teste t simples de grupos independentes pode ser realizado. Isso compara as médias dos dois grupos para determinar se eles são estatisticamente significativamente diferentes.\n\nImagine que o estudo está concluído; os dados são chamados de \"causal.csv\" e estão na pasta github deste laboratório.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#### LOAD DATA ####\nimport pandas as pd\ndat = pd.read_csv(\"datasets/causal.csv\")\n\n# Inspect data\nprint(dat.columns)\n\nprint('\\n')\nprint(dat.head())\n\nprint('\\n')\nprint(dat.group.unique())\n\ndat.describe()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "We see we have three variables, an unnamed id variable, a variable\nlisting the group, and the productivity scores of the employees on a 1-7\nscale. We want to compare the two groups, and we can do so by looking at\nthe means.\n\nWe can quickly request more detailed statistics. The values of `prod` can be grouped by the `group` using the Pandas `groupby` method. The mean of each group is then computed. The same recipe can be used to compute the standard deviation of the groups. \n___\nVemos que temos três variáveis, uma variável id não nomeada, uma variável listando o grupo e as pontuações de produtividade dos funcionários em uma escala de 1 a 7. Queremos comparar os dois grupos e podemos fazer isso observando as médias.\n\nPodemos solicitar estatísticas mais detalhadas rapidamente. Os valores de prod podem ser agrupados por grupo usando o método Pandas groupby. A média de cada grupo é então calculada. A mesma receita pode ser usada para calcular o desvio padrão dos grupos.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "dat[['group','prod']].groupby('group').mean()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "dat[['group','prod']].groupby('group').std()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "We see here that intervention group has a slightly higher average\nproductivity score. We can next test the null hypothesis to see if this\ndifference is significant.\n\nRecall that the null hypothesis always says that the **effect is absent\nin the population** and that the sample result is an artifact of random\nchance. In symbols, this means that the difference between the group\naverages is exactly zero in the population.\n___\nVemos aqui que o grupo de intervenção tem uma pontuação de produtividade média ligeiramente superior. Em seguida, podemos testar a hipótese nula para ver se essa diferença é significativa.\n\nLembre-se de que a hipótese nula sempre diz que o efeito está ausente na população e que o resultado da amostra é um artefato do acaso. Em símbolos, isso significa que a diferença entre as médias do grupo é exatamente zero na população.\n___\n\n*H*<sub>0</sub> : *μ*<sub>*g**r**o**u**p*1</sub> − *μ*<sub>*g**r**o**u**p*2</sub> = 0\n Remember that *μ* refers to the population average, so this is saying\nthat the population difference is exactly zero. Any difference observed\nin our sample is therefore due to random chance. We run our *t*-test to\nconsider this possibility.\n\nRecall that a *t*-test compares the size of the *observed difference*\n($\\bar{x}_{1} - \\bar{x}_{2}$) against the value in the null hypothesis\n(zero), divided by what is typically expected by chance:\n___\n$$t= \\frac{result - null }{chance}$$\n___\n\nH0: μgrupo1 - μgrupo2 = 0 Lembre-se de que μ se refere à média da população, então isso quer dizer que a diferença da população é exatamente zero. Qualquer diferença observada em nossa amostra deve-se, portanto, ao acaso. Executamos nosso teste t para considerar essa possibilidade.\n\nLembre-se de que um teste t compara o tamanho da diferença observada (𝑥¯1 − 𝑥¯2\n) contra o valor na hipótese nula (zero), dividido pelo que é normalmente esperado ao acaso:\n\n___\n For the two-group *t*-test, the \"result\" is the difference between the\ngroup averages in the sample, the \"null\" states the difference, and\n\"chance\" is the standard error of that difference.\n\nHow can we run our test? The default in R is to run the \"Welch\" version\nof the test. This version of the test does *not* make any assumptions\nabout the variances of the two groups.\n___\nPara o teste t de dois grupos, o \"resultado\" é a diferença entre as médias do grupo na amostra, o \"nulo\" indica a diferença e \"chance\" é o erro padrão dessa diferença.\n\nComo podemos fazer nosso teste? O padrão em R é executar a versão \"Welch\" do teste. Esta versão do teste não faz suposições sobre as variâncias dos dois grupos.\n\n___\n$$t'= \\frac{result - null }{chance}= \\frac{(\\bar{x}_{1}-\\bar{x}_{2}) - 0 }{\\sqrt{\\frac{\\hat{\\sigma}_1^2}{n_{1}}+\\frac{\\hat{\\sigma}_2^2}{n_{2}}}}$$\n The bottom looks complicated but is simply a measure of the standard\nerror of the size of the difference between our two groups. We can\nexplore the details of this equation in a later lab. For now, let's run\nthe test and interpret the result.\n\nThe Python code in the function below does the following:\n1. Compute the difference of means. \n2. The `ttest_ind` function from the scipy.stats package to compute the t statistic and p-value.\n3. The `tconfint_diff` function is used to compute the confidence interval.\n4. The `dof_satt` function estimates the degrees of freedom. \n___\nA parte inferior parece complicada, mas é simplesmente uma medida do erro padrão do tamanho da diferença entre nossos dois grupos. Podemos explorar os detalhes dessa equação em um laboratório posterior. Por enquanto, vamos fazer o teste e interpretar o resultado.\n\nO código Python na função abaixo faz o seguinte:\n\n1. Calcule a diferença de médias.\n2. A função ttest_ind do pacote scipy.stats para calcular a estatística t e o valor p.\n3. A função tconfint_diff é usada para calcular o intervalo de confiança.\n4. A função dof_satt estima os graus de liberdade.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def t_test_two_samp(df, alpha, alternative='two-sided'):\n    \n    a = df[df.group == 'control']['prod']\n    b = df[df.group == 'intervention']['prod']    \n    \n    diff = a.mean() - b.mean()\n\n    res = ss.ttest_ind(a, b)\n      \n    means = ws.CompareMeans(ws.DescrStatsW(a), ws.DescrStatsW(b))\n    confint = means.tconfint_diff(alpha=alpha, alternative=alternative, usevar='unequal') \n    degfree = means.dof_satt()\n\n    index = ['DegFreedom', 'Difference', 'Statistic', 'PValue', 'Low95CI', 'High95CI']\n    return pd.Series([degfree, diff, res[0], res[1], confint[0], confint[1]], index = index)   \n   \n\ntest = t_test_two_samp(dat, 0.05)\ntest",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "The *t*-value of 3.16 tells us that the difference between our groups\n(top of *t*-test fraction) is 3.16 times larger than would be expected\ntypically by chance (bottom of *t*-test fraction). How often would a\nresult this big happen if the null were actually true? The *p*-value is\n.002, so only 0.2% of the time. This is sufficient to reject the null\n(*p* &lt; .05), and we can conclude that our difference is not due to\nchance. We also have a 95% CI on the size of the difference, and we are\nfairly confident that the control group is .457 to 0.107 productivity\npoints lower than intervention group.\n\n___\n\nO valor t de 3,16 nos diz que a diferença entre nossos grupos (parte superior da fração do teste t) é 3,16 vezes maior do que seria esperado normalmente por acaso (parte inferior da fração do teste t). Com que frequência um resultado desse tamanho aconteceria se o nulo fosse realmente verdadeiro? O valor p é 0,002, portanto, apenas 0,2% do tempo. Isso é suficiente para rejeitar o nulo (p <0,05), e podemos concluir que nossa diferença não se deve ao acaso. Também temos um IC de 95% no tamanho da diferença e estamos bastante confiantes de que o grupo controle é 0,457 a 0,107 pontos de produtividade abaixo do grupo de intervenção.\n\n___\n\nImportantly, because we performed a randomized, controlled experiment,\nwe can conclude that this was actually the result of our treatment. This\nis a good sign, but the size of the improvement is small. We can\nconclude that our intervention **did** improve productivity, but it was\nonly by about a quarter of a point.\n\nHow big is that? Well, the scale is a 1-7 scale. We can try plotting the data using a boxplot of the two groups to visualize it. The Seaborn code in the cell below creates a boxplot of the `prod` values grouped by the `group` variable. A `swarmplot` is superimposed so you can see the position of the data points. The swarm plot shows a jittered display of the data points.    \n___\n\nImportante, porque realizamos um experimento controlado e randomizado, podemos concluir que esse foi realmente o resultado do nosso tratamento. Este é um bom sinal, mas o tamanho da melhoria é pequeno. Podemos concluir que nossa intervenção melhorou a produtividade, mas foi apenas em cerca de um quarto de ponto.\n\nQuão grande é isso? Bem, a escala é uma escala de 1-7. Podemos tentar plotar os dados usando um boxplot dos dois grupos para visualizá-los. O código Seaborn na célula abaixo cria um gráfico de caixa dos valores do produto agrupados pela variável de grupo. Um swarmplot é sobreposto para que você possa ver a posição dos pontos de dados. O gráfico de enxame mostra uma exibição tremida dos pontos de dados.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "ax = plt.figure(figsize=(8,8)).gca() # define axis\nsns.boxplot(x = 'group', y = 'prod', data = dat, ax = ax)\nsns.swarmplot(x = 'group', y = 'prod', color = 'black', data = dat, ax = ax, alpha = 0.4)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "![](M3_Lab3_-_Causal_Claim_files/figure-markdown_strict/unnamed-chunk-5-1.png)\n\nA violin plot might also help to visualize the differences. The code in the cell below follows the same recipe used above, but with the `violinplot` function. \n___\n\nUma trama de violino também pode ajudar a visualizar as diferenças. O código na célula abaixo segue a mesma receita usada acima, mas com a função violinplot.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "ax = plt.figure(figsize=(8,8)).gca() # define axis\nsns.violinplot(x = 'group', y = 'prod', data = dat, ax = ax)\nsns.swarmplot(x = 'group', y = 'prod', color = 'black', data = dat, ax = ax, alpha = 0.4)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "![](M3_Lab3_-_Causal_Claim_files/figure-markdown_strict/unnamed-chunk-7-1.png)\n\nWe see from the above plots that, although the effect was statistically significant, the\ndifference is fairly minimal.\n\nWe can estimate our effect size (Cohen's *d*) using the `tt_ind_solve_power`\nfunction from the `statsmodels.stats.power` package:\n\n___\n\n\nVemos pelas parcelas acima que, embora o efeito tenha sido estatisticamente significativo, a diferença é bastante mínima.\n\nPodemos estimar o tamanho do efeito (d de Cohen) usando a função tt_ind_solve_power do pacote statsmodels.stats.power:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#cohen.d(prod ~ group, data=dat)\ncontrol = dat[dat.group == 'control']['prod']\nintervention = dat[dat.group == 'intervention']['prod']\nprint(np.mean(intervention) - np.mean(control))\nratio = len(control)/len(intervention)\ntt_ind_solve_power(effect_size=None, nobs1 = len(control), alpha=0.05, power=0.8, ratio=ratio, alternative='two-sided')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "From these results you can see that the actual difference between these groups is a bit larger than Cohen's d required from 0.80 power.\n___\nA partir desses resultados, você pode ver que a diferença real entre esses grupos é um pouco maior do que o d de Cohen exigido da potência de 0,80.\n___\nConclusion\n==========\n\nThanks to this study, we can be fairly certain that the stress reduction\nintervention had an effect. However, the difference in the effect is\nminimal at best.\n___\nConclusão\n====\nGraças a este estudo, podemos estar bastante certos de que a intervenção de redução do estresse teve efeito. No entanto, a diferença no efeito é mínima.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}